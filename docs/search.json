[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "rowan-n.github.io",
    "section": "",
    "text": "This is a website I created for my Data Science class. It contains a page about me, as well as a dropdown of a few tidyverse data sets I’ve analysed.\nThis website will be expanded on over the course of the semester!\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "Rowan Norenberg is a linguistics, data science, and French student. When they’re not in class or studying, they perform in choir and run D&D campaigns for their friends.\n\n\nPomona College | Claremont, CA B.A. in Linguistics | Sept 2023 - June 2027"
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About",
    "section": "",
    "text": "Pomona College | Claremont, CA B.A. in Linguistics | Sept 2023 - June 2027"
  },
  {
    "objectID": "datavis.html",
    "href": "datavis.html",
    "title": "Data Viz",
    "section": "",
    "text": "Here’s where you describe your plots…\n\n\n\nHere’s where you describe dashboards…"
  },
  {
    "objectID": "datavis.html#tidy-verse-1",
    "href": "datavis.html#tidy-verse-1",
    "title": "Data Viz",
    "section": "",
    "text": "Here’s where you describe your plots…"
  },
  {
    "objectID": "datavis.html#tidy-verse-2",
    "href": "datavis.html#tidy-verse-2",
    "title": "Data Viz",
    "section": "",
    "text": "Here’s where you describe dashboards…"
  },
  {
    "objectID": "tidyv1.html",
    "href": "tidyv1.html",
    "title": "Tidy Tuesday - D&D Monsters",
    "section": "",
    "text": "This is a plot I made comparing the different types of D&D monsters with their total hit points and their strength score / modifier.\n\n\n\n\n\n\n\n\n\nTidyverse Link: https://github.com/rfordatascience/tidytuesday/tree/main/data/2024/2024-12-17\nDataset Citation: Harmon J (2025). dddata: Data from the Dungeons and Dragons System Reference Document. R package version 0.0.0.9000, https://github.com/jonthegeek/dddata."
  },
  {
    "objectID": "tidyv2.html",
    "href": "tidyv2.html",
    "title": "Tidy Tuesday - D&D Spells",
    "section": "",
    "text": "This is a plot I made trying to see which of the schools of magic had the longest spell range on average. This was made complicated by the spell range being stored as character strings (eg “30 feet” or “Touch”) so I made levels. Unfortunatley this doesn’t give a great representation at how different 300 feet is from 500 feet versus 5 feet from 10 feet. Work in progress.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTidyverse link: https://github.com/rfordatascience/tidytuesday/tree/main/data/2024/2024-12-17\nDataset Citation: Harmon J (2025). dddata: Data from the Dungeons and Dragons System Reference Document. R package version 0.0.0.9000, https://github.com/jonthegeek/dddata.\nData Source: https://www.dndbeyond.com/srd"
  },
  {
    "objectID": "tidyv3.html",
    "href": "tidyv3.html",
    "title": "Tidy Tuesday - Shakespeare",
    "section": "",
    "text": "The data from this page comes from Shakespeare’s works, which are in the public domain. The datasets used here pulled their data specifically from https://shakespeare.mit.edu/ and can be found in the TidyTeusday 2024 repository, curated by Nicola Rennie.\n\n\nShow the code\n#| echo: false\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(stringr)\nlibrary(forcats)\n\n\nhamlet &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-09-17/hamlet.csv')\nmacbeth &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-09-17/macbeth.csv')\nromeo_juliet &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2024/2024-09-17/romeo_juliet.csv')\n\n\n\n\nShow the code\ntragedies &lt;- bind_rows(\n  hamlet |&gt; mutate(play = \"Hamlet\"),\n  macbeth |&gt; mutate(play = \"Macbeth\"),\n  romeo_juliet |&gt; mutate(play = \"Romeo and Juliet\")\n)\n\n\ntragedies_ghosts &lt;- tragedies |&gt;\n  filter(str_detect(dialogue, \"\\\\b(ghost|witch|spirit)\\\\b\")) |&gt;\n  select(play, dialogue) |&gt;\n  mutate(supernatural = str_extract(str_to_lower(dialogue), \"\\\\b(ghost|witch|spirit)\\\\b\" )) |&gt;\n  count(play, supernatural, name = \"num_mentions\")\n\n\n\nggplot(tragedies_ghosts, aes(x = play, y = num_mentions, fill = supernatural)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Mentions of 'Ghost', 'Witch', and 'Spirit' in Shakespeare's Tragedies\",\n    x = \"Play\",\n    y = \"Number of Mentions\",\n    fill = \"\" \n    ) + \n  theme_minimal() + \n  theme(plot.title = element_text(size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nThis graph shows that Hamlet has a great deal many more mentions of ghosts, witches, and spirits than the other two plays. This indicates that ghosts, witches, and spirits are more relevant to the plot of Hamlet than to the other two, which makes sense because Hamlet is frequently seeing apparitions of his dead father and this is central to the plot.\n\n\nShow the code\ntragedies_exclaim &lt;- tragedies |&gt;\n  filter(str_detect(dialogue, \"(?i)\\\\bHamlet!+|Macbeth!+|Romeo!+|Juliet!+\")) |&gt;\n  mutate(exclamations = str_extract(dialogue, \"(?i)\\\\bHamlet!+|Macbeth!+|Romeo!+|Juliet!+\")) |&gt;\n  count(play, exclamations, name = \"num_exclaim\") |&gt;\n  mutate(exclamations = fct_relevel(exclamations, c(\"Hamlet!\", \"Macbeth!\", \"Romeo!\", \"Juliet!\")))\n\n\n\nggplot(tragedies_exclaim, aes(x = exclamations, y = num_exclaim, fill = exclamations)) +\n  geom_col(position = \"dodge\") +\n  labs(\n    title = \"Number of times the main character's name is exclaimed\",\n    x = \"Play\",\n    y = \"Number of Mentions\",\n    fill = \"\" \n    ) +\n  theme_minimal() + \n  theme(plot.title = element_text(size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nThis graph shows that out of the main characters from each play, Romeo is the one who gets yelled at (or about) the most.\n\n\nShow the code\ntragedies_exclaimers &lt;- tragedies |&gt;\n  filter(str_detect(dialogue, \"(?i)\\\\b(Hamlet|Macbeth|Romeo|Juliet)!+\")) |&gt; \n  mutate(\n    exclamations = str_extract(dialogue, \"(?i)\\\\b(Hamlet|Macbeth|Romeo|Juliet)!+\"),\n    exclamations = str_to_title(exclamations)  \n  ) |&gt;\n  count(play, character, exclamations, name = \"num_exclaim\") |&gt;\n  arrange(desc(num_exclaim))\n\n\ntop_exclaimers &lt;- tragedies_exclaimers |&gt; \n  slice_max(num_exclaim, n = 10)\n\nggplot(top_exclaimers, aes(\n  x = reorder(character, num_exclaim),\n  y = num_exclaim,\n  fill = exclamations\n)) +\n  geom_col() +\n  coord_flip() +\n  labs(\n    title = \"Top 10 Characters Who Shout Names the Most\",\n    subtitle = \"Colored by which name they exclaim\",\n    x = \"Character\",\n    y = \"Number of Exclamations\",\n    fill = \"Name Shouted\"\n  ) +\n  theme_minimal() + \n  theme(plot.title = element_text(size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nAnd this graph shows that not all of those times Romeo is yelled at are from Juliet’s famous line! Turns out Romeo is yelled at (or about) by a good variety of folks.\n\n\nShow the code\ntragedies_exclaimers &lt;- tragedies |&gt;\n  filter(str_detect(dialogue, \"(?i)!+\")) |&gt; \n  mutate(\n    exclamations = str_extract(dialogue, \"(?i)!+\"),\n    exclamations = str_to_title(exclamations)  \n  ) |&gt;\n  count(play, character, exclamations, name = \"num_exclaim\") |&gt;\n  arrange(desc(num_exclaim))\n\n# Optionally, focus on the top 10 loudest shouters\ntop_exclaimers &lt;- tragedies_exclaimers |&gt; \n  slice_max(num_exclaim, n = 10)\n\nggplot(top_exclaimers, aes(\n  x = reorder(character, num_exclaim),\n  y = num_exclaim,\n  fill = play\n)) +\n  geom_col(position = \"dodge\") +\n  coord_flip() +\n  labs(\n    title = \"Criers\",\n    subtitle = \"Characters in Shakespeare's Tragedies who Exclaim the Most\",\n    x = \"Character\",\n    y = \"Number of Exclamations\",\n    fill = \"\"\n  ) +\n  theme_minimal() + \n  theme(plot.title = element_text(size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\nFinally, this graph tells us that despite not being yelled at nearly as much as Romeo is, Hamlet yells a lot. Perhaps this is because of all of those ghosts, spirits, and witches.\nBelow is a graph for each play showing who has the most lines. These line counts graphs tell you which character is the “main character”, which, unsurprisingly, are also the title characters. But just in case.\n\n\nShow the code\nhamlet_counts &lt;- hamlet |&gt;\n  filter(!grepl(\"stage\", character, ignore.case = TRUE)) |&gt; \n  count(character, name = \"num_lines\") |&gt;\n  mutate(play = \"Hamlet\") |&gt;\n  arrange(desc(num_lines)) |&gt;\n  slice_head(n = 20)\n\n  \n  \nggplot(hamlet_counts, aes(x = reorder(character, num_lines), y = num_lines)) +\n  geom_col(fill = \"steelblue\") +\n  coord_flip() +\n  labs(\n    title = \"Hamlet: Number of Lines\",\n    x = \"Named Character\",\n    y = \"Total Number of Lines\"\n  ) +\n  theme_minimal(base_size = 14) +  # bigger text\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    axis.text.y = element_text(size = 10)\n  ) + \n  theme_minimal() + \n  theme(plot.title = element_text(size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nmacbeth_counts &lt;- macbeth |&gt;\n  filter(!grepl(\"stage\", character, ignore.case = TRUE)) |&gt; \n  count(character, name = \"num_lines\") |&gt;\n  mutate(play = \"Macbeth\") |&gt;\n  arrange(desc(num_lines)) |&gt;\n  slice_head(n = 20)\n\n  \n  \nggplot(macbeth_counts, aes(x = reorder(character, num_lines), y = num_lines)) +\n  geom_col(fill = \"goldenrod\") +\n  coord_flip() +\n  labs(\n    title = \"Macbeth: Number of Lines\",\n    x = \"Named Character\",\n    y = \"Total Number of Lines\"\n  ) +\n  theme_minimal(base_size = 14) +  # bigger text\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    axis.text.y = element_text(size = 10)\n  ) + \n  theme_minimal() + \n  theme(plot.title = element_text(size = 16, face = \"bold\"))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nromeo_juliet_counts &lt;- romeo_juliet |&gt;\n  filter(!grepl(\"stage\", character, ignore.case = TRUE)) |&gt; \n  count(character, name = \"num_lines\") |&gt;\n  mutate(play = \"Romeo and Juliet\") |&gt;\n  arrange(desc(num_lines)) |&gt;\n  slice_head(n = 20)\n\n  \n  \nggplot(romeo_juliet_counts, aes(x = reorder(character, num_lines), y = num_lines)) +\n  geom_col(fill = \"maroon\") +\n  coord_flip() +\n  labs(\n    title = \"Romeo and Juliet: Number of Lines\",\n    x = \"Named Character\",\n    y = \"Total Number of Lines\"\n  ) +\n  theme_minimal(base_size = 14) +  # bigger text\n  theme(\n    plot.title = element_text(size = 18, face = \"bold\"),\n    axis.text.y = element_text(size = 10)\n  ) + \n  theme_minimal() + \n  theme(plot.title = element_text(size = 16, face = \"bold\"))"
  },
  {
    "objectID": "project4.html",
    "href": "project4.html",
    "title": "project4",
    "section": "",
<<<<<<< HEAD
    "text": "In 2015, “OkCupid Data for Introductory Statistics and Data Science Courses” by Albert Y. Kim and Adriana Escobedo-Land was published to the academic journal Taylor & Francis online. The dataset was published with the intention of being used for teaching data science and statistics. However, by 2016, the dataset was already appearing in magazines like Fortune, with those who had encountered the dataset claiming the dataset was found to have identifiable information – that is, someone reading the dataset could identify the real person that the OkCupid profile data was scraped from. The dating profile contained extremely sensitive information, ranging from job, salary, age, and height to religion, sexual orientation, and drug use. Being able to identify someone easily from a large, easy to access dataset led to calls for review of the dataset.\nConsent\nNone of the participants consented to be part of the dataset. In the OkCupid privacy policy, users agree to their information being visible to other members on the service, and their data being shared with service providers and operating partner companies. The privacy policy repeatedly insists that privacy and consent are important to the company. It is not unreasonable for a user to read this policy and assume that their personal data would not be scraped for a public database. However, the creators of the dataset were given permission not by the individual participants but rather by the president and founders of the company. The data scraping was thus not illegal. However, Tiffany Xiao &Yifan Ma (2021) points out that legislation about technology and data are outdated, and that while privacy violations are not often illegal, they are still immoral.\nAnonymity\nThe data was found to have identifiable information. The data is from the 2010s, so the data is certainly not old enough to be anonymous. The data contained physical descriptions including height, body type, and race, as well as age, religion, occupation, sex, education, pets, children, and star sign. They also included 10 essay questions which were answered by participants. That combined with the knowledge that all of these people lived within 25 miles of San Francisco – at an exact date which was later removed – and you can definitely identify participants. The data was not at all anonymized until reviews were requested, when essay questions were randomized by row, the exact date was replaced with “from the 2010s”, and random noise was added to the age variable.\nParticipants\nGeneralizing people by sexual orientation is not an algorithm that should be created. That sort of data can be used for little good and substantial harm. To my knowledge the dataset is not currently being used for unintended purposes, but this is not a good precedent to set. Mass amounts of personal information can be easily used for systemic discrimination.\nAvailability\nThis data was made publicly available on GitHub, as well as accessible through Taylor & Francis. You can see and access the data freely online.\nKim, A. Y., & Escobedo-Land, A. (2015). OkCupid Data for Introductory Statistics and Data Science Courses. Journal of Statistics Education, 23(2). https://doi.org/10.1080/10691898.2015.11889737\nPrivacy policy – okcupid. (n.d.-a). https://okcupid-app.zendesk.com/hc/en-us/articles/22780694078491-Privacy-Policy\nXiao, T., & Ma, Y. (2021). A Letter to the Journal of Statistics and Data Science Education — A Call for Review of “OkCupid Data for Introductory Statistics and Data Science Courses” by Albert Y. Kim and Adriana Escobedo-Land. Journal of Statistics and Data Science Education, 29(2), 214–215. https://doi.org/10.1080/26939169.2021.1930812"
=======
    "text": "In 2015, “OkCupid Data for Introductory Statistics and Data Science Courses” by Albert Y. Kim and Adriana Escobedo-Land was published to the academic journal Taylor & Francis online. The dataset was published with the intention of being used for teaching data science and statistics. However, by 2016, the dataset was already appearing in magazines like Fortune, with those who had encountered the dataset claiming the dataset was found to have identifiable information – that is, someone reading the dataset could identify the real person that the OkCupid profile data was scraped from. The dating profile contained extremely sensitive information, ranging from job, salary, age, and height to religion, sexual orientation, and drug use. Being able to identify someone easily from a large, easy to access dataset led to calls for review of the dataset.\nConsent None of the participants consented to be part of the dataset. In the OkCupid privacy policy, users agree to their information being visible to other members on the service, and their data being shared with service providers and operating partner companies. The privacy policy repeatedly insists that privacy and consent are important to the company. It is not unreasonable for a user to read this policy and assume that their personal data would not be scraped for a public database. However, the creators of the dataset were given permission not by the individual participants but rather by the president and founders of the company. The data scraping was thus not illegal. However, Tiffany Xiao &Yifan Ma (2021) points out that legislation about technology and data are outdated, and that while privacy violations are not often illegal, they are still immoral.\nAnonymity The data was found to have identifiable information. The data is from the 2010s, so the data is certainly not old enough to be anonymous. The data contained physical descriptions including height, body type, and race, as well as age, religion, occupation, sex, education, pets, children, and star sign. They also included 10 essay questions which were answered by participants. That combined with the knowledge that all of these people lived within 25 miles of San Francisco – at an exact date which was later removed – and you can definitely identify participants. The data was not at all anonymized until reviews were requested, when essay questions were randomized by row, the exact date was replaced with “from the 2010s”, and random noise was added to the age variable.\nParticipants Generalizing people by sexual orientation is not an algorithm that should be created. That sort of data can be used for little good and substantial harm. To my knowledge the dataset is not currently being used for unintended purposes, but this is not a good precedent to set. Mass amounts of personal information can be easily used for systemic discrimination.\nAvailability This data was made publicly available on GitHub, as well as accessible through Taylor & Francis. You can see and access the data freely online.\nKim, A. Y., & Escobedo-Land, A. (2015). OkCupid Data for Introductory Statistics and Data Science Courses. Journal of Statistics Education, 23(2). https://doi.org/10.1080/10691898.2015.11889737\nPrivacy policy – okcupid. (n.d.-a). https://okcupid-app.zendesk.com/hc/en-us/articles/22780694078491-Privacy-Policy\nXiao, T., & Ma, Y. (2021). A Letter to the Journal of Statistics and Data Science Education — A Call for Review of “OkCupid Data for Introductory Statistics and Data Science Courses” by Albert Y. Kim and Adriana Escobedo-Land. Journal of Statistics and Data Science Education, 29(2), 214–215. https://doi.org/10.1080/26939169.2021.1930812"
>>>>>>> 07150f516c0f69180791172b3c33bf4b211e2728
  },
  {
    "objectID": "Project3.html",
    "href": "Project3.html",
    "title": "Project 3",
    "section": "",
    "text": "For Project 3 you will conduct a small simulation study that conducts a permutation test by simulating behavior under the null hypothesis (you will need to find a dataset and develop a related research question). Please include the full context of the problem. That is, what are the variables and why is testing them interesting? Include a visualization of the original data / variables of interest so that the reader can sense the extent of difference in the original relationship.\nYour simulation study should contain the following elements:\nat least 1 function you’ve written at least 1 map() variant a description of the simulation. Help the reader follow what you are doing, that is, what does your function do? why would you map it? etc. at least 1 illustrative, well-labeled plot a description of what insights can be gained from your plot(s) Logistics:\nstart by describing what you plan to do (3-4 sentences). end with a description of what you did (3-4 sentences). That is, use words to guide the reader through your analysis. please include all your code used in the analysis (but feel free to use code folding1). make sure that all graphs are well-labeled (including x and y axes, title of the graph, and accurate and succinct labels for color and fill). do not include error or warning messages (see HW YAML for code). include a few sentences describing each of your plots or tables. That is, tell the reader what they see when they look at the plot. Your narrative description should be in the text part of the qmd file, not as a comment in an R chunk. if you used data, include the source of the data. Include both where you got the data (e.g., the TidyTuesday URL) and also the original provenance of the information. if you are working with a (local) copy of the .csv file (as opposed to, for example, a link to the dataset on TidyTuesday’s GitHub site), then the .csv file should live in your GitHub repository for your website. And you should read the data in from that local copy. That is, the dataset should not live in your Downloads. Timeline Project 3 must be submitted on Canvas (not Gradescope) by 11:59 PM on Thursday October 30, 2025. You will add a tab to your Quarto webpage and submit the new page’s URL. [Remember, you should continue to work in your website Rproj. Do not start a new R Project.]"
  }
]